{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1. Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src import (\n",
    "    merge_csv,\n",
    "    prepare_external_data,\n",
    "    generate_full_data,\n",
    "    resample_data_by_10min,\n",
    "    merge_external,\n",
    "    encode_datetime,\n",
    "    add_location_details,\n",
    "    parse_target,\n",
    "    create_samples,\n",
    "    train_and_predict, \n",
    "    create_ensemble_submission\n",
    ")\n",
    "\n",
    "output_folder = Path(\"AICUP\")\n",
    "external_data_folder = Path(\"ExternalData\")\n",
    "\n",
    "input_folder = [Path(\"TrainingData\"), Path(\"TrainingData_Additional\")]\n",
    "upload_template = Path(\"TestSet_SubmissionTemplate/upload(no answer).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2. Data Preprocessing (optional)\n",
    "Skip this step if you already have `train_x.csv`, `train_y.csv`, and `test_x.csv` in your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = merge_csv(input_folder, output_folder)\n",
    "external_data = prepare_external_data(external_data_folder, output_folder)\n",
    "\n",
    "data = (\n",
    "    generate_full_data(training_data, start_time=\"08:00\", end_time=\"16:59\")\n",
    "    .pipe(resample_data_by_10min)\n",
    "    .dropna()\n",
    "    .pipe(merge_external, external_data)\n",
    "    .pipe(encode_datetime)\n",
    "    .pipe(add_location_details)\n",
    ")\n",
    "\n",
    "reference_data = data.copy()\n",
    "feature_columns = [col for col in data.columns if col not in [\n",
    "    \"DateTime\", \"WindSpeed(m/s)\", \"Pressure(hpa)\", \"Temperature(°C)\", \n",
    "    \"Humidity(%)\", \"Sunlight(Lux)\", \"Power(mW)\"\n",
    "]]\n",
    "create_samples(data, external_data, reference_data, feature_columns, output_folder)\n",
    "\n",
    "upload = (\n",
    "    pd.read_csv(upload_template)\n",
    "    .pipe(parse_target)\n",
    "    .pipe(merge_external, external_data)\n",
    "    .pipe(encode_datetime)\n",
    "    .pipe(add_location_details)\n",
    ")\n",
    "create_samples(upload, external_data, reference_data, feature_columns, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"train\": {\n",
    "        \"X\": pd.read_csv(f\"{output_folder}/train_x.csv\"),\n",
    "        \"y\": pd.read_csv(f\"{output_folder}/train_y.csv\").squeeze()\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"X\": pd.read_csv(f\"{output_folder}/test_x.csv\")\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Shapes of the data:\")\n",
    "print(f\"Train X: {dataset['train']['X'].shape}\")\n",
    "print(f\"Train y: {dataset['train']['y'].shape}\")\n",
    "print(f\"Test X: {dataset['test']['X'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4. Model Training (CatBoost、LightGBM、XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=int(1e7), task_type=\"GPU\", verbose=int(1e5))\n",
    "train_and_predict(\n",
    "    model=model,\n",
    "    model_name=\"catboost\",\n",
    "    dataset=dataset,\n",
    "    upload_template=upload_template,\n",
    "    output_folder=output_folder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(num_leaves=int(2**15 - 1))\n",
    "train_and_predict(\n",
    "    model=model,\n",
    "    model_name=\"lightgbm\",\n",
    "    dataset=dataset,\n",
    "    upload_template=upload_template,\n",
    "    output_folder=output_folder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=int(1e6), learning_rate=0.001, tree_method=\"hist\", device=\"cuda\")\n",
    "train_and_predict(\n",
    "    model=model,\n",
    "    model_name=\"xgboost\",\n",
    "    dataset=dataset,\n",
    "    upload_template=upload_template,\n",
    "    output_folder=output_folder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ensemble_submission(\n",
    "    model_preds=[\n",
    "        output_folder / \"catboost_pred.csv\",\n",
    "        output_folder / \"lightgbm_pred.csv\",\n",
    "        output_folder / \"xgboost_pred.csv\"\n",
    "    ],\n",
    "    upload_template=upload_template,\n",
    "    output_file= output_folder / \"submission.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
