{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src import (\n",
    "    Dataset,\n",
    "    resample_data_by_10min,\n",
    "    generate_full_data,\n",
    "    filter_nan_days,\n",
    "    encode_datetime,\n",
    "    merge_external,\n",
    "    parse_target,\n",
    "    post_process,\n",
    "    calculate_metrics,\n",
    "    create_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def pre_process(self, data, upload):\n",
    "        dataset = {\"train\": {}, \"test\": {}}\n",
    "        feature_columns = [\n",
    "            \"LocationCode\", \"month\", \"day\", \"hour\", \"minute\", \"timestamp\",\n",
    "            \"PS01\",\"PS02\",\"TX01\",\"TD01\",\"RH01\",\"WD01\",\"WD02\",\"WD07\",\"WD08\",\"PP01\",\"SS01\",\"GR01\",\"TS03\"\n",
    "        ]\n",
    "        target_column = [\"Power(mW)\"]\n",
    "\n",
    "        data = (\n",
    "            generate_full_data(data, start_time=\"09:00\", end_time=\"16:59\")\n",
    "            .pipe(resample_data_by_10min)\n",
    "            .pipe(filter_nan_days)\n",
    "            .pipe(merge_external, external_file=\"data/10min.csv\")\n",
    "            .pipe(encode_datetime)\n",
    "        )\n",
    "\n",
    "        dataset[\"train\"] = create_samples(data, data, feature_columns, target_column)\n",
    "\n",
    "        if upload is not None:\n",
    "            upload = (\n",
    "                parse_target(upload)\n",
    "                .pipe(merge_external, external_file=\"data/10min.csv\")\n",
    "                .pipe(encode_datetime)\n",
    "            )\n",
    "            dataset[\"test\"] = create_samples(upload, data, feature_columns, target_column)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "dataset = CustomDataset(data_file=\"./data/all_data.csv\",upload_file=\"./data/upload.csv\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "lgbm = LGBMRegressor(num_leaves=4095, verbosity=1)\n",
    "kf = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(lgbm, dataset[\"train\"][\"X\"], dataset[\"train\"][\"y\"], cv=kf, scoring=\"neg_mean_absolute_error\", )\n",
    "\n",
    "print(\"Average MAE:\", -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(num_leaves=4095, verbosity=-1)\n",
    "lgbm.fit(dataset[\"train\"][\"X\"], dataset[\"train\"][\"y\"])\n",
    "calculate_metrics(dataset[\"train\"][\"y\"], lgbm.predict(dataset[\"train\"][\"X\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgbm.predict(dataset[\"test\"][\"X\"])\n",
    "upload = pd.read_csv(\"data/upload.csv\")\n",
    "upload[\"答案\"] = post_process(predictions)\n",
    "upload.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(lgbm, \"lgbm.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
